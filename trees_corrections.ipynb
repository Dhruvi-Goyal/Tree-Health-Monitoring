{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVkfo_w4CY09",
        "outputId": "af91bbbe-1cd7-4b4c-938b-279215826967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import time\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import statistics as st\n",
        "import matplotlib.pyplot as plt\n",
        "import ee\n",
        "import ast"
      ],
      "metadata": {
        "id": "KP3EWR7ICgvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# acz_list = ['Western Himalayan Region', 'Eastern Himalayan Region', 'Lower Gangetic Plain Region',\n",
        "#             'Middle Gangetic Plain Region', 'Upper Gangetic Plain Region', 'Trans Gangetic Plain Region',\n",
        "#             'Eastern Plateau & Hills Region', 'Central Plateau & Hills Region', 'Western Plateau and Hills Region',\n",
        "#             'Southern Plateau and Hills Region', 'East Coast Plains & Hills Region']\n",
        "\n",
        "acz_list = ['Eastern Plateau & Hills Region']"
      ],
      "metadata": {
        "id": "F8dpZZchCirK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_month_dict = {'Eastern Plateau & Hills Region': 'cc_12',\n",
        "                   'Middle Gangetic Plain Region': 'cc_10',\n",
        "                   'Lower Gangetic Plain Region': 'cc_9',\n",
        "                   'Western Himalayan Region': 'cc_8',\n",
        "                   'Eastern Himalayan Region': 'cc_10',\n",
        "                   'Upper Gangetic Plain Region': 'cc_9',\n",
        "                   'Trans Gangetic Plain Region': 'cc_9',\n",
        "                   'Central Plateau & Hills Region': 'cc_7',\n",
        "                   'Western Plateau and Hills Region': 'cc_11',\n",
        "                   'Southern Plateau and Hills Region': 'cc_8',\n",
        "                   'East Coast Plains & Hills Region': 'cc_12'}"
      ],
      "metadata": {
        "id": "T2DABMXPCmO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if AY 2023's data is being added, set year = '2023'\n",
        "year = '2022'"
      ],
      "metadata": {
        "id": "Ox6-6SrSDOVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to correct data from year_2 and year_1\n",
        "year_1 = int(year)-1\n",
        "year_2 = int(year)-2\n",
        "year_3 = int(year)-3\n",
        "year_4 = int(year)-4"
      ],
      "metadata": {
        "id": "tD7xuYmTDdCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Correction - CCD\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a832NIR4CseW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corrections(df):\n",
        "    columns = list(df.columns)\n",
        "    n = len(columns)\n",
        "\n",
        "    # In case the no. of columns are too less for any corrections to be performed\n",
        "    if n < 5:\n",
        "        correction_df = pd.DataFrame(columns=columns)\n",
        "        return correction_df\n",
        "\n",
        "    # Correcting the second last year\n",
        "    correction_df = df[(df[columns[n-1]] == df[columns[n-3]]) & (df[columns[n-3]] == df[columns[n-4]]) & (df[columns[n-2]] != df[columns[n-1]])]\n",
        "    correction_df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Correcting the middle year\n",
        "    new_df = df[(df[columns[n-5]] == df[columns[n-4]]) & (df[columns[n-4]] == df[columns[n-2]]) & (df[columns[n-2]] == df[columns[n-1]]) & (df[columns[n-3]] != df[columns[n-5]])]\n",
        "    correction_df = pd.concat([correction_df, new_df], ignore_index=True)\n",
        "    correction_df.drop_duplicates(inplace=True)\n",
        "    del(new_df)\n",
        "\n",
        "    # Actually Performing the corrections once all rows where corrections need to be performed are found\n",
        "    correction_df.loc[(correction_df[columns[n-1]] == correction_df[columns[n-3]]) & (correction_df[columns[n-3]] == correction_df[columns[n-4]]) & (correction_df[columns[n-2]] != correction_df[columns[n-1]]), columns[n-2]] = correction_df[columns[n-1]]\n",
        "    correction_df.loc[(correction_df[columns[n-5]] == correction_df[columns[n-4]]) & (correction_df[columns[n-4]] == correction_df[columns[n-2]]) & (correction_df[columns[n-2]] == correction_df[columns[n-1]]) & (correction_df[columns[n-3]] != correction_df[columns[n-5]]), columns[n-3]] = correction_df[columns[n-5]]\n",
        "\n",
        "    return correction_df"
      ],
      "metadata": {
        "id": "MyVlgZhcC5Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for agroclimatic_zone in acz_list:\n",
        "    print(agroclimatic_zone)\n",
        "    df = pd.read_csv(f'drive/MyDrive/harsh/{agroclimatic_zone}.csv')\n",
        "    dist_list = list(df['Name'])\n",
        "    print(f'len(dist_list): {len(dist_list)}')\n",
        "\n",
        "    path = f'drive/MyDrive/{agroclimatic_zone}/'\n",
        "\n",
        "    total_corrections = 0\n",
        "    total_length = 0\n",
        "\n",
        "    for i in range(len(dist_list)):\n",
        "\n",
        "        # if i != 11:\n",
        "        #   continue\n",
        "\n",
        "        print(i, dist_list[i])\n",
        "        file_4 = path + dist_list[i] + f\"/{year_4}/result_monthly_cc.csv\"\n",
        "        file_3 = path + dist_list[i] + f\"/{year_3}/result_monthly_cc.csv\"\n",
        "        file_2 = path + dist_list[i] + f\"/{year_2}/result_monthly_cc.csv\"\n",
        "        file_1 = path + dist_list[i] + f\"/{year_1}/result_monthly_cc.csv\"\n",
        "        file_0 = path + dist_list[i] + f\"/{year}/result_monthly_cc.csv\"\n",
        "\n",
        "        band = best_month_dict[agroclimatic_zone]\n",
        "        columnList = ['cc_1', 'cc_2', 'cc_3', 'cc_4', 'cc_5', 'cc_6', 'cc_7', 'cc_8', 'cc_9', 'cc_10', 'cc_11', 'cc_12']\n",
        "        columnList.remove(band)\n",
        "\n",
        "        try:\n",
        "            df_4 = pd.read_csv(file_4)\n",
        "            df_4.drop(columns=columnList, inplace=True)\n",
        "            df_4.rename(columns={band: 'cover_class'}, inplace=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_4 = pd.DataFrame(columns=['.geo', 'cover_class'])\n",
        "\n",
        "        try:\n",
        "            df_3 = pd.read_csv(file_3)\n",
        "            df_3.drop(columns=columnList, inplace=True)\n",
        "            df_3.rename(columns={band: 'cover_class'}, inplace=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_3 = pd.DataFrame(columns=['.geo', 'cover_class'])\n",
        "\n",
        "        df_4.rename(columns={'cover_class': f'cc_{year_4}'}, inplace=True)\n",
        "        df_3.rename(columns={'cover_class': f'cc_{year_3}'}, inplace=True)\n",
        "        merged_df = pd.merge(df_4, df_3, on='.geo', how='outer')\n",
        "        del(df_4)\n",
        "        del(df_3)\n",
        "\n",
        "        try:\n",
        "            df_2 = pd.read_csv(file_2)\n",
        "            df_2.drop(columns=columnList, inplace=True)\n",
        "            df_2.rename(columns={band: 'cover_class'}, inplace=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_2 = pd.DataFrame(columns=['.geo', 'cover_class'])\n",
        "\n",
        "        df_2.rename(columns={'cover_class': f'cc_{year_2}'}, inplace=True)\n",
        "        merged_df = pd.merge(merged_df, df_2, on='.geo', how='outer')\n",
        "        del(df_2)\n",
        "\n",
        "        try:\n",
        "            df_1 = pd.read_csv(file_1)\n",
        "            df_1.drop(columns=columnList, inplace=True)\n",
        "            df_1.rename(columns={band: 'cover_class'}, inplace=True)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_1 = pd.DataFrame(columns=['.geo', 'cover_class'])\n",
        "\n",
        "        df_1.rename(columns={'cover_class': f'cc_{year_1}'}, inplace=True)\n",
        "        merged_df = pd.merge(merged_df, df_1, on='.geo', how='outer')\n",
        "        del(df_1)\n",
        "\n",
        "        try:\n",
        "            df_0 = pd.read_csv(file_0)\n",
        "            df_0.drop(columns=columnList, inplace=True)\n",
        "            df_0.rename(columns={band: 'cover_class'}, inplace=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_0 = pd.DataFrame(columns=['.geo', 'cover_class'])\n",
        "\n",
        "        df_0.rename(columns={'cover_class': f'cc_{year}'}, inplace=True)\n",
        "        merged_df = pd.merge(merged_df, df_0, on='.geo', how='outer')\n",
        "        del(df_0)\n",
        "\n",
        "\n",
        "        merged_df = merged_df[['.geo', f'cc_{year_4}', f'cc_{year_3}', f'cc_{year_2}', f'cc_{year_1}', f'cc_{year}']]\n",
        "        total_length += len(merged_df)\n",
        "        print(\"Length of merged_df:\", len(merged_df))\n",
        "        print(\"Total Length:\", total_length)\n",
        "        correction_df = corrections(merged_df)\n",
        "        del(merged_df)\n",
        "        total_corrections += len(correction_df)\n",
        "        print(f'Correction_df length: {len(correction_df)}')\n",
        "        print(f'Total Corrections: {total_corrections}')\n",
        "        if len(correction_df) > 0:\n",
        "            correction_year_2 = correction_df[['.geo', f'cc_{year_2}']]\n",
        "            correction_year_1 = correction_df[['.geo', f'cc_{year_1}']]\n",
        "            correction_year_2.to_csv(f'{path}{dist_list[i]}/{year_2}/result_monthly_cc_corrections.csv', index=False)\n",
        "            correction_year_1.to_csv(f'{path}{dist_list[i]}/{year_1}/result_monthly_cc_corrections.csv', index=False)\n",
        "\n",
        "        del(correction_df)"
      ],
      "metadata": {
        "id": "yFHm-bfOCoOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fawkMbjGNmgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Correction - CH"
      ],
      "metadata": {
        "id": "BwZGDcD1OS0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column Order\n",
        "# ['.geo',\n",
        "# 'rh98_{year_4}', 'rh98_{year_3}', 'rh98_{year_2}', 'rh98_{year_1}', 'rh98_{year}',\n",
        "# 'rh75_{year_4}', 'rh75_{year_3}', 'rh75_{year_2}', 'rh75_{year_1}', 'rh75_{year}',\n",
        "# 'rh50_{year_4}', 'rh50_{year_3}', 'rh50_{year_2}', 'rh50_{year_1}', 'rh50_{year}']\n",
        "\n",
        "\n",
        "def corrections(df):\n",
        "    columns = list(df.columns)\n",
        "    n = len(columns)\n",
        "\n",
        "    # Correcting the second last year - rh98\n",
        "    correction_df = df[(df[columns[5]] == df[columns[3]]) & (df[columns[3]] == df[columns[2]]) & (df[columns[4]] != df[columns[5]])]\n",
        "    correction_df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Correcting the middle year - rh98\n",
        "    new_df = df[(df[columns[1]] == df[columns[2]]) & (df[columns[2]] == df[columns[4]]) & (df[columns[4]] == df[columns[5]]) & (df[columns[3]] != df[columns[1]])]\n",
        "    correction_df = pd.concat([correction_df, new_df], ignore_index=True)\n",
        "    correction_df.drop_duplicates(inplace=True)\n",
        "    del(new_df)\n",
        "\n",
        "\n",
        "    # Correcting the second last year - rh75\n",
        "    new_df = df[(df[columns[10]] == df[columns[8]]) & (df[columns[8]] == df[columns[7]]) & (df[columns[9]] != df[columns[10]])]\n",
        "    correction_df = pd.concat([correction_df, new_df], ignore_index=True)\n",
        "    del(new_df)\n",
        "    correction_df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Correcting the middle year - rh75\n",
        "    new_df = df[(df[columns[6]] == df[columns[7]]) & (df[columns[7]] == df[columns[9]]) & (df[columns[9]] == df[columns[10]]) & (df[columns[8]] != df[columns[6]])]\n",
        "    correction_df = pd.concat([correction_df, new_df], ignore_index=True)\n",
        "    correction_df.drop_duplicates(inplace=True)\n",
        "    del(new_df)\n",
        "\n",
        "\n",
        "    # Correcting the second last year - rh50\n",
        "    new_df = df[(df[columns[15]] == df[columns[13]]) & (df[columns[13]] == df[columns[12]]) & (df[columns[14]] != df[columns[15]])]\n",
        "    correction_df = pd.concat([correction_df, new_df], ignore_index=True)\n",
        "    del(new_df)\n",
        "    correction_df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Correcting the middle year - rh50\n",
        "    new_df = df[(df[columns[11]] == df[columns[12]]) & (df[columns[12]] == df[columns[14]]) & (df[columns[14]] == df[columns[15]]) & (df[columns[13]] != df[columns[11]])]\n",
        "    correction_df = pd.concat([correction_df, new_df], ignore_index=True)\n",
        "    correction_df.drop_duplicates(inplace=True)\n",
        "    del(new_df)\n",
        "\n",
        "\n",
        "    # Actually Performing the corrections once all rows where corrections need to be performed are found\n",
        "\n",
        "    # rh98\n",
        "    correction_df.loc[(correction_df[columns[5]] == correction_df[columns[3]]) & (correction_df[columns[3]] == correction_df[columns[2]]) & (correction_df[columns[4]] != correction_df[columns[5]]), columns[4]] = correction_df[columns[5]]\n",
        "    correction_df.loc[(correction_df[columns[1]] == correction_df[columns[2]]) & (correction_df[columns[2]] == correction_df[columns[4]]) & (correction_df[columns[4]] == correction_df[columns[5]]) & (correction_df[columns[3]] != correction_df[columns[1]]), columns[3]] = correction_df[columns[1]]\n",
        "\n",
        "\n",
        "    # rh75\n",
        "    correction_df.loc[(correction_df[columns[10]] == correction_df[columns[8]]) & (correction_df[columns[8]] == correction_df[columns[7]]) & (correction_df[columns[9]] != correction_df[columns[10]]), columns[9]] = correction_df[columns[10]]\n",
        "    correction_df.loc[(correction_df[columns[6]] == correction_df[columns[7]]) & (correction_df[columns[7]] == correction_df[columns[9]]) & (correction_df[columns[9]] == correction_df[columns[10]]) & (correction_df[columns[8]] != correction_df[columns[6]]), columns[8]] = correction_df[columns[6]]\n",
        "\n",
        "\n",
        "    # rh50\n",
        "    correction_df.loc[(correction_df[columns[15]] == correction_df[columns[13]]) & (correction_df[columns[13]] == correction_df[columns[12]]) & (correction_df[columns[14]] != correction_df[columns[15]]), columns[14]] = correction_df[columns[15]]\n",
        "    correction_df.loc[(correction_df[columns[11]] == correction_df[columns[12]]) & (correction_df[columns[12]] == correction_df[columns[14]]) & (correction_df[columns[14]] == correction_df[columns[15]]) & (correction_df[columns[13]] != correction_df[columns[11]]), columns[13]] = correction_df[columns[11]]\n",
        "\n",
        "    return correction_df"
      ],
      "metadata": {
        "id": "FbnepTZ4OXvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert string representation of list to an actual list\n",
        "def convert_to_list(string):\n",
        "    return ast.literal_eval(string)\n",
        "\n",
        "\n",
        "for agroclimatic_zone in acz_list:\n",
        "    print(agroclimatic_zone)\n",
        "\n",
        "    df = pd.read_csv('drive/MyDrive/harsh/district_to_agroclimaticZone_mapping.csv')\n",
        "    df['IntersectingZones'] = df['IntersectingZones'].apply(convert_to_list)\n",
        "    district_mapping_df = df[df['AgroclimaticZone'] == agroclimatic_zone][['District', 'IntersectingZones']]\n",
        "    dist_list = []\n",
        "    for ind in district_mapping_df.index:\n",
        "        district = district_mapping_df.loc[ind, 'District']\n",
        "        zones = district_mapping_df['IntersectingZones'][ind]\n",
        "        dist_list.append(district)\n",
        "\n",
        "\n",
        "    print(f'len(dist_list): {len(dist_list)}')\n",
        "\n",
        "    path = f'drive/MyDrive/{agroclimatic_zone}/'\n",
        "\n",
        "    total_corrections = 0\n",
        "    total_length = 0\n",
        "\n",
        "    for i in range(len(dist_list)):\n",
        "\n",
        "        # if i != 11:\n",
        "        #   continue\n",
        "\n",
        "        print(i, dist_list[i])\n",
        "        file_4 = path + dist_list[i] + f\"/{year_4}/result_chm.csv\"\n",
        "        file_3 = path + dist_list[i] + f\"/{year_3}/result_chm.csv\"\n",
        "        file_2 = path + dist_list[i] + f\"/{year_2}/result_chm.csv\"\n",
        "        file_1 = path + dist_list[i] + f\"/{year_1}/result_chm.csv\"\n",
        "        file_0 = path + dist_list[i] + f\"/{year}/result_chm.csv\"\n",
        "\n",
        "        try:\n",
        "            df_4 = pd.read_csv(file_4)\n",
        "            df_4.rename(columns={'rh98_class': f'rh98_{year_4}', 'rh75_class': f'rh75_{year_4}', 'rh50_class': f'rh50_{year_4}'}, inplace=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_4 = pd.DataFrame(columns=['.geo', f'rh98_{year_4}', f'rh75_{year_4}', f'rh50_{year_4}', f'ch_{year_4}'])\n",
        "\n",
        "        try:\n",
        "            df_3 = pd.read_csv(file_3)\n",
        "            df_3.rename(columns={'rh98_class': f'rh98_{year_3}', 'rh75_class': f'rh75_{year_3}', 'rh50_class': f'rh50_{year_3}'}, inplace=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_3 = pd.DataFrame(columns=['.geo', f'rh98_{year_3}', f'rh75_{year_3}', f'rh50_{year_3}', f'ch_{year_3}'])\n",
        "\n",
        "        merged_df = pd.merge(df_4, df_3, on='.geo', how='outer')\n",
        "        del(df_4)\n",
        "        del(df_3)\n",
        "\n",
        "        try:\n",
        "            df_2 = pd.read_csv(file_2)\n",
        "            df_2.rename(columns={'rh98_class': f'rh98_{year_2}', 'rh75_class': f'rh75_{year_2}', 'rh50_class': f'rh50_{year_2}'}, inplace=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_2 = pd.DataFrame(columns=['.geo', f'rh98_{year_2}', f'rh75_{year_2}', f'rh50_{year_2}', f'ch_{year_2}'])\n",
        "\n",
        "        merged_df = pd.merge(merged_df, df_2, on='.geo', how='outer')\n",
        "        del(df_2)\n",
        "\n",
        "        try:\n",
        "            df_1 = pd.read_csv(file_1)\n",
        "            df_1.rename(columns={'rh98_class': f'rh98_{year_1}', 'rh75_class': f'rh75_{year_1}', 'rh50_class': f'rh50_{year_1}'}, inplace=True)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_1 = pd.DataFrame(columns=['.geo', f'rh98_{year_1}', f'rh75_{year_1}', f'rh50_{year_1}', f'ch_{year_1}'])\n",
        "\n",
        "        merged_df = pd.merge(merged_df, df_1, on='.geo', how='outer')\n",
        "        del(df_1)\n",
        "\n",
        "        try:\n",
        "            df_0 = pd.read_csv(file_0)\n",
        "            df_0.rename(columns={'rh98_class': f'rh98_{year}', 'rh75_class': f'rh75_{year}', 'rh50_class': f'rh50_{year}'}, inplace=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            df_0 = pd.DataFrame(columns=['.geo', f'rh98_{year}', f'rh75_{year}', f'rh50_{year}', f'ch_{year}'])\n",
        "\n",
        "        merged_df = pd.merge(merged_df, df_0, on='.geo', how='outer')\n",
        "        del(df_0)\n",
        "\n",
        "        merged_df = merged_df[['.geo', f'rh98_{year_4}', f'rh98_{year_3}', f'rh98_{year_2}', f'rh98_{year_1}', f'rh98_{year}', f'rh75_{year_4}', f'rh75_{year_3}', f'rh75_{year_2}', f'rh75_{year_1}', f'rh75_{year}', f'rh50_{year_4}', f'rh50_{year_3}', f'rh50_{year_2}', f'rh50_{year_1}', f'rh50_{year}']]\n",
        "        total_length += len(merged_df)\n",
        "        print(\"Length of merged_df:\", len(merged_df))\n",
        "        print(\"Total Length:\", total_length)\n",
        "        correction_df = corrections(merged_df)\n",
        "        del(merged_df)\n",
        "        total_corrections += len(correction_df)\n",
        "        print(f'Correction_df length: {len(correction_df)}')\n",
        "        print(f'Total Corrections: {total_corrections}')\n",
        "        if len(correction_df) > 0:\n",
        "\n",
        "            choices = [0, 0, 1, 2, 1, 2]\n",
        "\n",
        "\n",
        "            conditions = [\n",
        "                (correction_df[f'rh50_{year_4}'] == 0) & (correction_df[f'rh75_{year_4}'] == 0) & (correction_df[f'rh98_{year_4}'] == 0),\n",
        "                (correction_df[f'rh50_{year_4}'] == 0) & (correction_df[f'rh75_{year_4}'] == 0) & (correction_df[f'rh98_{year_4}'] == 1),\n",
        "                (correction_df[f'rh50_{year_4}'] == 0) & (correction_df[f'rh75_{year_4}'] == 1) & (correction_df[f'rh98_{year_4}'] == 0),\n",
        "                (correction_df[f'rh50_{year_4}'] == 0) & (correction_df[f'rh75_{year_4}'] == 1) & (correction_df[f'rh98_{year_4}'] == 1),\n",
        "                (correction_df[f'rh50_{year_4}'] == 1) & (correction_df[f'rh75_{year_4}'] == 0) & (correction_df[f'rh98_{year_4}'] == 0),\n",
        "                (correction_df[f'rh50_{year_4}'] == 1) & (correction_df[f'rh75_{year_4}'] == 0) & (correction_df[f'rh98_{year_4}'] == 1)\n",
        "            ]\n",
        "            correction_df[f'ch_{year_4}'] = np.select(conditions, choices, default=3)\n",
        "\n",
        "\n",
        "            conditions = [\n",
        "                (correction_df[f'rh50_{year_3}'] == 0) & (correction_df[f'rh75_{year_3}'] == 0) & (correction_df[f'rh98_{year_3}'] == 0),\n",
        "                (correction_df[f'rh50_{year_3}'] == 0) & (correction_df[f'rh75_{year_3}'] == 0) & (correction_df[f'rh98_{year_3}'] == 1),\n",
        "                (correction_df[f'rh50_{year_3}'] == 0) & (correction_df[f'rh75_{year_3}'] == 1) & (correction_df[f'rh98_{year_3}'] == 0),\n",
        "                (correction_df[f'rh50_{year_3}'] == 0) & (correction_df[f'rh75_{year_3}'] == 1) & (correction_df[f'rh98_{year_3}'] == 1),\n",
        "                (correction_df[f'rh50_{year_3}'] == 1) & (correction_df[f'rh75_{year_3}'] == 0) & (correction_df[f'rh98_{year_3}'] == 0),\n",
        "                (correction_df[f'rh50_{year_3}'] == 1) & (correction_df[f'rh75_{year_3}'] == 0) & (correction_df[f'rh98_{year_3}'] == 1)\n",
        "            ]\n",
        "            correction_df[f'ch_{year_3}'] = np.select(conditions, choices, default=3)\n",
        "\n",
        "\n",
        "            conditions = [\n",
        "                (correction_df[f'rh50_{year_2}'] == 0) & (correction_df[f'rh75_{year_2}'] == 0) & (correction_df[f'rh98_{year_2}'] == 0),\n",
        "                (correction_df[f'rh50_{year_2}'] == 0) & (correction_df[f'rh75_{year_2}'] == 0) & (correction_df[f'rh98_{year_2}'] == 1),\n",
        "                (correction_df[f'rh50_{year_2}'] == 0) & (correction_df[f'rh75_{year_2}'] == 1) & (correction_df[f'rh98_{year_2}'] == 0),\n",
        "                (correction_df[f'rh50_{year_2}'] == 0) & (correction_df[f'rh75_{year_2}'] == 1) & (correction_df[f'rh98_{year_2}'] == 1),\n",
        "                (correction_df[f'rh50_{year_2}'] == 1) & (correction_df[f'rh75_{year_2}'] == 0) & (correction_df[f'rh98_{year_2}'] == 0),\n",
        "                (correction_df[f'rh50_{year_2}'] == 1) & (correction_df[f'rh75_{year_2}'] == 0) & (correction_df[f'rh98_{year_2}'] == 1)\n",
        "            ]\n",
        "            correction_df[f'ch_{year_2}'] = np.select(conditions, choices, default=3)\n",
        "\n",
        "\n",
        "            conditions = [\n",
        "                (correction_df[f'rh50_{year_1}'] == 0) & (correction_df[f'rh75_{year_1}'] == 0) & (correction_df[f'rh98_{year_1}'] == 0),\n",
        "                (correction_df[f'rh50_{year_1}'] == 0) & (correction_df[f'rh75_{year_1}'] == 0) & (correction_df[f'rh98_{year_1}'] == 1),\n",
        "                (correction_df[f'rh50_{year_1}'] == 0) & (correction_df[f'rh75_{year_1}'] == 1) & (correction_df[f'rh98_{year_1}'] == 0),\n",
        "                (correction_df[f'rh50_{year_1}'] == 0) & (correction_df[f'rh75_{year_1}'] == 1) & (correction_df[f'rh98_{year_1}'] == 1),\n",
        "                (correction_df[f'rh50_{year_1}'] == 1) & (correction_df[f'rh75_{year_1}'] == 0) & (correction_df[f'rh98_{year_1}'] == 0),\n",
        "                (correction_df[f'rh50_{year_1}'] == 1) & (correction_df[f'rh75_{year_1}'] == 0) & (correction_df[f'rh98_{year_1}'] == 1)\n",
        "            ]\n",
        "            correction_df[f'ch_{year_1}'] = np.select(conditions, choices, default=3)\n",
        "\n",
        "\n",
        "            conditions = [\n",
        "                (correction_df[f'rh50_{year}'] == 0) & (correction_df[f'rh75_{year}'] == 0) & (correction_df[f'rh98_{year}'] == 0),\n",
        "                (correction_df[f'rh50_{year}'] == 0) & (correction_df[f'rh75_{year}'] == 0) & (correction_df[f'rh98_{year}'] == 1),\n",
        "                (correction_df[f'rh50_{year}'] == 0) & (correction_df[f'rh75_{year}'] == 1) & (correction_df[f'rh98_{year}'] == 0),\n",
        "                (correction_df[f'rh50_{year}'] == 0) & (correction_df[f'rh75_{year}'] == 1) & (correction_df[f'rh98_{year}'] == 1),\n",
        "                (correction_df[f'rh50_{year}'] == 1) & (correction_df[f'rh75_{year}'] == 0) & (correction_df[f'rh98_{year}'] == 0),\n",
        "                (correction_df[f'rh50_{year}'] == 1) & (correction_df[f'rh75_{year}'] == 0) & (correction_df[f'rh98_{year}'] == 1)\n",
        "            ]\n",
        "            correction_df[f'ch_{year}'] = np.select(conditions, choices, default=3)\n",
        "\n",
        "            cols = correction_df.columns\n",
        "            for j in range(1, len(cols)):\n",
        "                correction_df[cols[j]] = correction_df[cols[j]].astype('Int64')\n",
        "\n",
        "            correction_year_2 = correction_df[['.geo', f'rh50_{year_2}', f'rh75_{year_2}', f'rh98_{year_2}', f'ch_{year_2}']]\n",
        "            correction_year_1 = correction_df[['.geo', f'rh50_{year_1}', f'rh75_{year_1}', f'rh98_{year_1}', f'ch_{year_1}']]\n",
        "            correction_year_2.to_csv(f'{path}{dist_list[i]}/{year_2}/result_chm_corrections.csv', index=False)\n",
        "            correction_year_1.to_csv(f'{path}{dist_list[i]}/{year_1}/result_chm_corrections.csv', index=False)\n",
        "\n",
        "        del(correction_df)"
      ],
      "metadata": {
        "id": "1MbnG_BaRFLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ucfnvTPcUHag"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}